{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projeto 1: Classificação Binária - Brest Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etapa 1: Importação das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.0+cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etapa 2: Base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x159090f5cb0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mesmo número aleatório\n",
    "np.random.seed(123)\n",
    "torch.manual_seed(123) # Mesmos pesos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores = pd.read_csv('Arquivos/entradas_breast.csv')\n",
    "classes = pd.read_csv('Arquivos/saidas_breast.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores_treinamento, previsores_teste, classe_treinamento, classe_teste = train_test_split(previsores, classes, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classe_teste.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etapa 3: Transformação dos dados para tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(previsores_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.array(previsores_treinamento))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy array para tensores\n",
    "previsores_treinamento = torch.tensor(np.array(previsores_treinamento),dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classe_treinamento = torch.tensor(np.array(classe_treinamento),dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um dataset com previsores e classe treinamento, identificando quem é o previsor e quem é a classe\n",
    "dataset = torch.utils.data.TensorDataset(previsores_treinamento, classe_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataset.TensorDataset"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch trabalha com mini batches, por isso precisa de um dataLoader \n",
    "# (significa que eu enviarei 10 registros por rodada para carregar os pesos)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etapa 4: Construção do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 neuronios na camada de entrada -> 2 camadas ocultas:  30 -> 16n -> 16n -> 1 \n",
    "# (entradas + saídas)/2 = (30+1)/2 = 16\n",
    "\n",
    "#Sequential -> Sequencia de camadas\n",
    "classificador = nn.Sequential(\n",
    "    nn.Linear(in_features=30, out_features=16), # Camada tipo densa, liga em todas os neuronios\n",
    "    nn.ReLU(), # Função de ativação aplicada nos primeiros 16 neuronios\n",
    "    nn.Linear(16, 16), # Nova ligação\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16,1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Sequential(\n",
       "  (0): Linear(in_features=30, out_features=16, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=16, out_features=1, bias=True)\n",
       "  (5): Sigmoid()\n",
       ")>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificador.parameters # da pra tirar o bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss() # Erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otimizador = Adam, usando os parametros, o learning rate, \n",
    "# weight_decay que é a cada número X de épocas ele diminui o LR pra chegar ao mínimo global\n",
    "optimizer = torch.optim.Adam(classificador.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etapa 5: Treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1: perda 10.783365549043168\n",
      "Época 2: perda 2.848594320894674\n",
      "Época 3: perda 1.6747931701152823\n",
      "Época 4: perda 1.114138968115629\n",
      "Época 5: perda 0.6399635447319164\n",
      "Época 6: perda 0.6375325613243635\n",
      "Época 7: perda 0.5806612684283146\n",
      "Época 8: perda 0.5545990104938663\n",
      "Época 9: perda 0.5561710509449936\n",
      "Época 10: perda 0.5332180665329446\n",
      "Época 11: perda 0.5579720432328623\n",
      "Época 12: perda 0.5381610570258872\n",
      "Época 13: perda 0.5293807910625324\n",
      "Época 14: perda 0.3322672736506129\n",
      "Época 15: perda 0.5136039808045986\n",
      "Época 16: perda 0.3553202749598165\n",
      "Época 17: perda 0.49602397141415017\n",
      "Época 18: perda 0.3320764961630799\n",
      "Época 19: perda 0.2934870313159948\n",
      "Época 20: perda 0.2504585366262946\n",
      "Época 21: perda 0.29526589464309605\n",
      "Época 22: perda 0.4988823265357073\n",
      "Época 23: perda 0.4724078536640073\n",
      "Época 24: perda 0.45883112054231556\n",
      "Época 25: perda 0.2754426968478879\n",
      "Época 26: perda 0.23398832794885302\n",
      "Época 27: perda 0.2637262643249922\n",
      "Época 28: perda 0.24135816097259521\n",
      "Época 29: perda 0.2827521181383798\n",
      "Época 30: perda 0.22670113100388714\n",
      "Época 31: perda 0.1930007252755553\n",
      "Época 32: perda 0.2224674918797127\n",
      "Época 33: perda 0.20293835862431414\n",
      "Época 34: perda 0.20900382699314937\n",
      "Época 35: perda 0.20249942577508992\n",
      "Época 36: perda 0.2026853388132051\n",
      "Época 37: perda 0.1884980160569729\n",
      "Época 38: perda 0.22386484107998914\n",
      "Época 39: perda 0.22917815414798814\n",
      "Época 40: perda 0.2006821985042459\n",
      "Época 41: perda 0.1863003436443504\n",
      "Época 42: perda 0.17895905112544463\n",
      "Época 43: perda 0.17074970277242882\n",
      "Época 44: perda 0.16809356333904488\n",
      "Época 45: perda 0.18588574002172017\n",
      "Época 46: perda 0.2094295196408449\n",
      "Época 47: perda 0.17474165937841632\n",
      "Época 48: perda 0.23269020549433175\n",
      "Época 49: perda 0.18479627218952965\n",
      "Época 50: perda 0.15981847290382828\n",
      "Época 51: perda 0.16683348991669888\n",
      "Época 52: perda 0.17472182779551246\n",
      "Época 53: perda 0.17108250236095385\n",
      "Época 54: perda 0.17865711242653604\n",
      "Época 55: perda 0.19238634752975994\n",
      "Época 56: perda 0.22095987412991913\n",
      "Época 57: perda 0.19898211189307446\n",
      "Época 58: perda 0.19104784666452296\n",
      "Época 59: perda 0.1418494035491211\n",
      "Época 60: perda 0.15667147098412348\n",
      "Época 61: perda 0.164136347133493\n",
      "Época 62: perda 0.1520091428659683\n",
      "Época 63: perda 0.1376710925792712\n",
      "Época 64: perda 0.1497876891368177\n",
      "Época 65: perda 0.15951062216921602\n",
      "Época 66: perda 0.2401576191836665\n",
      "Época 67: perda 0.15982165315383395\n",
      "Época 68: perda 0.14614047433336286\n",
      "Época 69: perda 0.14855387477680695\n",
      "Época 70: perda 0.16408250302206293\n",
      "Época 71: perda 0.14189275855003575\n",
      "Época 72: perda 0.16291084437262873\n",
      "Época 73: perda 0.12452205723736348\n",
      "Época 74: perda 0.13969860922241972\n",
      "Época 75: perda 0.14281798251579667\n",
      "Época 76: perda 0.13049976109137196\n",
      "Época 77: perda 0.12366287802281074\n",
      "Época 78: perda 0.14824780061581108\n",
      "Época 79: perda 0.2150658869162895\n",
      "Época 80: perda 0.20203269723542902\n",
      "Época 81: perda 0.23469147043909097\n",
      "Época 82: perda 0.17315295903380354\n",
      "Época 83: perda 0.1223451741429609\n",
      "Época 84: perda 0.12801343418094654\n",
      "Época 85: perda 0.12390760888973641\n",
      "Época 86: perda 0.12617339671394506\n",
      "Época 87: perda 0.15494806759146063\n",
      "Época 88: perda 0.12228451433136713\n",
      "Época 89: perda 0.15672460166455873\n",
      "Época 90: perda 0.12975315764806297\n",
      "Época 91: perda 0.1611095787090964\n",
      "Época 92: perda 0.14349459454980354\n",
      "Época 93: perda 0.10268857647383282\n",
      "Época 94: perda 0.13340976494256146\n",
      "Época 95: perda 0.11103925265934925\n",
      "Época 96: perda 0.12442584712664749\n",
      "Época 97: perda 0.13024597626915851\n",
      "Época 98: perda 0.12410301580851854\n",
      "Época 99: perda 0.13988068144833452\n",
      "Época 100: perda 0.13600782237860354\n"
     ]
    }
   ],
   "source": [
    "# Atualiza os pesos nesse for\n",
    "# 426 registros atualizados de 10 em 10, ou seja vai ter um ajuste de pesos 42,6x em cada época do for, ou seja 4.260x\n",
    "for epoch in range(100):\n",
    "    running_loss = 0.\n",
    "    \n",
    "    for data in train_loader:\n",
    "        inputs, labels = data # input entradas, labels dados reais | data roda cada batch\n",
    "        optimizer.zero_grad() # zera os valores acumulados, pra poder apontar pra uma nova direção no ajuste dos pesos\n",
    "        \n",
    "        outputs = classificador(inputs) #classificador.forward(inputs)\n",
    "        loss = criterion(outputs, labels) # Calculo do erro\n",
    "        #print('Loss')\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step() # Vai atualizar os pesos\n",
    "        running_loss += loss.item() #loss.item pega o valor do erro\n",
    "    print(f'Época {epoch+1}: perda {running_loss/len(train_loader)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etapa 6: Visualização dos pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-6.9537e-02, -7.6251e-02, -1.7509e-01,  5.4204e-02, -1.5442e-01,\n",
       "           1.0065e-01, -1.3578e-01, -1.2356e-01, -2.2725e-01,  1.9374e-01,\n",
       "          -3.4267e-02,  5.8904e-02, -1.2563e-01, -8.7217e-02, -3.5901e-04,\n",
       "          -2.2019e-01, -3.9123e-01, -1.2445e-02,  1.3856e-01,  2.4448e-03,\n",
       "           1.4020e-01, -4.8890e-02, -3.3449e-02,  1.4495e-01,  4.9342e-01,\n",
       "           1.2753e-01, -1.8688e-01,  3.9847e-02,  2.8978e-01,  4.1387e-02],\n",
       "         [ 1.9539e-01,  2.0192e-01,  2.8234e-01,  9.1706e-02, -1.3019e-01,\n",
       "          -7.7657e-02, -4.8287e-02, -1.3043e-01, -4.6018e-02,  2.6494e-01,\n",
       "          -5.9741e-02, -9.3107e-02, -2.0819e-03,  1.8033e-01, -5.0927e-03,\n",
       "          -9.2861e-02, -1.1140e-02,  1.9047e-01,  1.0000e-01, -1.4144e-02,\n",
       "           9.8384e-02,  5.3950e-02,  1.8551e-01,  4.1831e-04, -1.6448e-02,\n",
       "          -2.3621e-01, -1.6503e-01, -8.6718e-03, -6.3805e-02, -1.6640e-01],\n",
       "         [-1.2157e-02, -4.5317e-02, -2.4382e-01, -1.0570e-01, -9.9634e-03,\n",
       "           5.0544e-02,  3.2754e-02,  1.6623e-02, -9.7602e-02,  2.8518e-01,\n",
       "           1.6180e-01,  9.3185e-02, -1.1620e-01, -3.4289e-03, -1.1539e-03,\n",
       "          -2.4636e-01,  2.8207e-02,  8.7694e-04,  3.4154e-01, -4.5140e-04,\n",
       "           3.7205e-02, -1.8139e-01, -7.6016e-02, -1.0258e-03, -2.6413e-01,\n",
       "          -1.2432e-01, -1.7695e-01,  9.8322e-02,  2.3275e-02, -9.0592e-03],\n",
       "         [-3.7208e-01,  4.1547e-02, -1.5304e-01,  8.8715e-02, -1.8680e-01,\n",
       "          -1.8333e-02,  7.1596e-03,  4.2689e-02,  1.3150e-01, -2.2073e-01,\n",
       "           1.9073e-01, -1.5305e-01,  3.6852e-02,  1.2990e-02, -3.6266e-04,\n",
       "           5.1183e-02,  2.2570e-02, -8.2687e-03,  1.4464e-01,  4.8479e-03,\n",
       "           5.8626e-02, -1.5630e-01, -7.5106e-02,  1.5170e-02,  2.4111e-01,\n",
       "           8.4098e-02,  2.4124e-02,  2.4312e-01,  1.1355e-01,  3.9679e-01],\n",
       "         [-4.3357e-01, -3.9462e-02, -1.3677e-01, -1.3401e-01,  3.7850e-01,\n",
       "           3.4363e-02,  1.1986e-01, -3.1987e-01, -3.0203e-01,  2.3847e-01,\n",
       "          -1.8979e-01,  2.6087e-02, -1.5674e-02,  6.5712e-02,  4.2756e-02,\n",
       "          -3.1816e-01, -3.0037e-01, -2.2399e-01,  3.4493e-01,  2.3942e-01,\n",
       "          -2.9464e-01, -9.4262e-03, -1.6922e-01,  2.4669e-01, -3.4302e-03,\n",
       "          -8.0764e-02, -4.2520e-01, -1.0965e-01, -2.3407e-03,  5.0446e-01],\n",
       "         [ 2.8404e-02, -1.4107e-02,  1.1102e-01,  1.0879e-01,  5.5796e-02,\n",
       "           4.2099e-01, -7.5994e-02,  3.1389e-01,  2.0983e-01, -9.6094e-02,\n",
       "           1.4318e-01,  1.5400e-01, -1.0834e-01,  1.3934e-01, -1.8004e-03,\n",
       "           3.2087e-01,  1.8999e-01,  1.0694e-01, -2.6697e-01, -8.8991e-02,\n",
       "           2.8595e-02, -1.7895e-01,  3.7859e-02, -2.1833e-02, -1.9340e-01,\n",
       "          -1.1177e-02, -7.0179e-02,  2.5824e-01,  7.3466e-02, -2.5215e-01],\n",
       "         [-4.5899e-03,  2.5723e-02,  3.0429e-01, -1.1577e-01, -2.2323e-01,\n",
       "          -5.3055e-01, -2.8124e-02, -2.6426e-02,  2.2736e-01,  2.4246e-02,\n",
       "          -1.0645e-01, -2.4698e-01,  6.0224e-02,  5.4536e-02, -1.3672e-03,\n",
       "          -2.3603e-02,  7.6553e-02, -6.2570e-03,  2.9065e-01, -5.3652e-03,\n",
       "           1.2864e-02, -6.5811e-02,  2.0337e-01, -9.6635e-02, -2.8902e-01,\n",
       "           1.2236e-01,  1.9427e-01, -2.0618e-01, -2.5784e-01,  5.2674e-02],\n",
       "         [-2.8814e-01, -1.1936e-02, -1.3632e-01, -1.7103e-01,  3.4398e-01,\n",
       "          -2.3001e-02,  5.1845e-03, -1.8859e-02, -5.0937e-02, -4.9122e-02,\n",
       "          -8.5479e-02, -1.1210e-01,  6.9473e-02,  1.0536e-01,  3.5077e-03,\n",
       "           2.0951e-02, -1.0831e-01,  1.3315e-02, -2.7941e-01,  8.1686e-03,\n",
       "          -2.1089e-01,  8.5634e-02, -2.9390e-01,  9.4985e-02, -4.6387e-02,\n",
       "          -2.9478e-01,  4.1883e-02,  1.1845e-01, -3.1749e-02,  5.3517e-02],\n",
       "         [ 8.5973e-02, -1.5864e-01, -3.8438e-01, -3.9313e-02,  3.7651e-01,\n",
       "           1.2726e-01, -4.0954e-01, -1.0380e-01,  1.1364e-01,  2.0713e-01,\n",
       "           1.7097e-01, -3.0458e-02,  1.1033e-01,  3.7491e-02,  7.6883e-03,\n",
       "          -1.3592e-01,  4.1649e-03, -2.6945e-01,  4.1645e-01, -2.4793e-02,\n",
       "          -2.5158e-01, -4.8356e-02, -2.9716e-01,  2.0864e-01, -5.2920e-02,\n",
       "           1.9009e-01, -7.5869e-02,  1.9982e-01,  1.0361e-01,  2.7149e-01],\n",
       "         [-2.5574e-02,  1.4385e-01,  2.8989e-01,  1.6649e-02, -3.2659e-01,\n",
       "          -1.4918e-01, -8.5333e-02,  1.6691e-01,  4.5100e-02,  1.0509e-01,\n",
       "           1.1071e-01, -1.7552e-01,  1.5138e-01, -1.7264e-01, -8.7220e-03,\n",
       "           2.8647e-02,  1.6278e-01,  1.2109e-01,  1.3263e-01, -2.0531e-01,\n",
       "           1.8701e-01, -1.4560e-01,  3.1272e-01, -7.4984e-02,  1.3513e-01,\n",
       "           4.5559e-03, -7.5659e-03, -9.7024e-02,  8.9418e-02, -1.4925e-01],\n",
       "         [-1.3947e-01, -4.5819e-02,  4.1106e-02,  1.9231e-02, -4.9399e-02,\n",
       "          -1.0014e-01, -1.3327e-01, -1.2580e-01,  2.6688e-01,  4.5126e-02,\n",
       "          -1.2524e-01,  5.0679e-02, -1.1162e-01,  2.3974e-01, -3.0105e-03,\n",
       "          -7.1421e-02, -7.2132e-02, -3.3844e-01, -1.5641e-01,  1.5949e-03,\n",
       "          -2.0297e-01, -9.3920e-02,  4.8712e-02,  1.2287e-01,  2.9328e-01,\n",
       "          -1.6325e-01,  3.2059e-01,  2.2422e-01, -1.3585e-01, -2.7697e-02],\n",
       "         [ 6.8920e-02, -6.9314e-03,  1.3242e-01,  1.4913e-01, -5.7865e-02,\n",
       "           2.2269e-01, -1.3074e-01,  2.5067e-01,  1.9640e-01, -1.0274e-01,\n",
       "           1.4753e-02,  8.7765e-02, -1.5469e-02, -3.2735e-01, -1.5268e-02,\n",
       "           3.4772e-01,  2.7749e-03,  3.3015e-01, -2.3611e-01, -1.9761e-01,\n",
       "           2.0629e-01, -4.1265e-02,  3.0519e-01, -1.3225e-01, -2.2216e-01,\n",
       "           1.9389e-01,  3.7359e-02,  7.9449e-02,  1.2713e-01, -4.6492e-01],\n",
       "         [ 1.1813e-01,  5.6344e-02, -2.5749e-01, -5.5530e-02,  1.4007e-01,\n",
       "           2.0926e-01,  2.5149e-01,  4.7492e-02, -7.5797e-02, -2.5795e-01,\n",
       "           1.2910e-01, -4.0053e-02,  1.0827e-01,  7.1895e-02, -4.1414e-03,\n",
       "          -5.1035e-02,  3.8708e-03,  2.2812e-02, -2.8202e-01,  1.6070e-01,\n",
       "           6.1531e-02,  1.4741e-01, -2.6971e-02,  4.3637e-02, -4.1293e-02,\n",
       "           1.2581e-01, -9.8662e-04, -2.5549e-01,  8.5642e-02,  1.1677e-01],\n",
       "         [ 8.9813e-02, -1.1062e-01, -1.0879e-01,  1.4312e-02,  6.2214e-02,\n",
       "           4.7760e-03, -1.2587e-01,  6.7915e-02, -4.6284e-02, -1.8729e-01,\n",
       "           1.7709e-01, -1.1360e-01, -1.6870e-01,  1.4722e-01,  2.9263e-03,\n",
       "           1.0901e-02,  1.5890e-01, -1.0866e-01,  3.4335e-01,  3.7819e-03,\n",
       "           1.2217e-01, -3.0380e-02, -8.9205e-02,  1.4773e-01, -2.6031e-02,\n",
       "          -2.0584e-01, -6.6943e-02,  9.8351e-02,  1.1043e-01,  2.4176e-02],\n",
       "         [ 5.7721e-02, -2.3592e-02,  4.5249e-02, -1.2951e-01, -1.8510e-16,\n",
       "          -6.3558e-13,  7.4083e-11, -9.6452e-40, -2.5953e-02,  2.1831e-23,\n",
       "          -6.8755e-05, -2.1425e-02, -2.5864e-02, -3.5407e-02,  2.4080e-39,\n",
       "           1.5248e-39, -1.5475e-02, -1.1091e-39,  2.1476e-39, -2.8391e-40,\n",
       "           7.1263e-02,  8.6059e-02, -1.0550e-01, -1.7020e-01, -8.6335e-13,\n",
       "          -7.4117e-04,  2.7547e-06, -2.9729e-20, -1.4382e-06, -4.0465e-18],\n",
       "         [ 1.3325e-39,  1.1001e-39, -3.1409e-39,  2.8056e-39, -1.8799e-38,\n",
       "           5.3558e-39,  3.4472e-39,  3.8796e-39,  4.0491e-39, -4.4325e-39,\n",
       "           8.9301e-40, -2.7318e-12, -7.1439e-09, -4.5373e-39,  2.7663e-39,\n",
       "           7.5756e-38, -3.2428e-39,  3.7162e-39,  3.0898e-39,  6.8631e-40,\n",
       "           4.5290e-42, -1.1572e-40,  4.4366e-39, -1.2287e-27, -1.5276e-40,\n",
       "           3.6535e-41, -3.1894e-40,  6.3204e-39, -8.6743e-40, -6.3596e-39]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-1.7289e-01,  2.5812e-01, -2.4078e-01, -2.5088e-01, -7.7969e-01,\n",
       "          1.9780e-01,  1.8324e-01, -2.7474e-01, -3.6954e-01,  4.3157e-01,\n",
       "         -2.7658e-01,  4.3270e-01, -2.9234e-01, -4.5448e-02, -1.1203e-03,\n",
       "         -3.8596e-39], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.8818e-02, -2.5119e-02, -1.4728e-02,  4.1639e-02, -2.0576e-02,\n",
       "          -1.0380e-02, -1.8663e-02,  5.9078e-39, -1.5581e-01, -1.8276e-01,\n",
       "          -2.0229e-01,  5.6195e-02,  1.6687e-01,  2.1726e-01,  3.4539e-02,\n",
       "          -1.3156e-39],\n",
       "         [ 3.6425e-02, -1.5821e-01,  6.7020e-02,  8.0086e-03,  3.4502e-02,\n",
       "           1.4051e-01,  4.3843e-39, -1.1133e-39,  1.4594e-02, -2.5376e-01,\n",
       "          -4.3012e-02, -5.5309e-02, -1.7473e-01,  2.4221e-01,  9.5697e-40,\n",
       "           6.5725e-39],\n",
       "         [ 2.4084e-01, -5.1521e-02,  1.5345e-01,  1.5600e-01,  3.5906e-01,\n",
       "          -1.0434e-01, -5.3369e-02, -8.6447e-02,  2.3797e-01,  5.1289e-02,\n",
       "          -1.4032e-02, -3.8504e-03,  2.2111e-01,  8.2521e-02,  6.6199e-02,\n",
       "          -7.1817e-03],\n",
       "         [-9.9619e-02,  7.8632e-02,  4.5475e-02, -2.0033e-01, -4.3833e-02,\n",
       "           5.5006e-02,  2.3646e-02, -6.4444e-02,  1.9550e-01,  8.4653e-02,\n",
       "          -3.1703e-01,  2.8814e-01,  1.6056e-01,  1.3820e-01,  9.9777e-02,\n",
       "           1.0746e-02],\n",
       "         [ 1.0320e-01,  1.2978e-02, -3.9706e-04, -2.5067e-01,  5.8588e-02,\n",
       "          -4.5426e-01,  1.1938e-01,  2.5044e-01,  3.2828e-02,  8.1144e-03,\n",
       "          -1.9822e-01,  1.0890e-01, -7.0344e-02, -7.9921e-02, -8.5179e-02,\n",
       "          -2.7008e-27],\n",
       "         [ 1.0252e-01, -7.2825e-02,  1.8825e-03, -1.5358e-01, -8.2428e-02,\n",
       "           6.2373e-02,  3.2815e-39,  1.0607e-39, -7.9802e-02, -1.0453e-01,\n",
       "          -1.0131e-01,  1.3115e-01, -1.8316e-01,  8.3768e-02,  2.9154e-04,\n",
       "          -3.0405e-39],\n",
       "         [-1.2349e-01, -5.3179e-02,  5.0471e-02, -3.1560e-03,  1.6810e-01,\n",
       "           1.5260e-01,  4.1579e-02, -1.2959e-01, -1.3979e-01, -2.0680e-01,\n",
       "           8.1711e-02,  1.6173e-02,  2.0637e-01,  2.2360e-01,  5.2271e-02,\n",
       "          -6.0324e-09],\n",
       "         [ 1.0659e-01,  2.7895e-02, -1.3532e-01, -5.3600e-02, -3.1044e-01,\n",
       "           1.2755e-01, -1.9410e-01, -1.4669e-01, -5.4976e-02,  1.4511e-01,\n",
       "           8.4266e-02,  6.7846e-02, -8.3976e-02, -1.9253e-01,  8.5261e-40,\n",
       "          -3.4370e-39],\n",
       "         [-1.2693e-01,  1.9368e-01, -1.7168e-01, -1.0897e-01,  1.7545e-01,\n",
       "           1.2651e-01,  1.4118e-01,  1.2832e-01, -8.1961e-02, -1.4043e-01,\n",
       "           9.0138e-02,  8.5436e-02, -4.9194e-02,  2.0475e-01, -1.1642e-01,\n",
       "           7.2249e-10],\n",
       "         [ 1.9067e-01,  1.2141e-01, -1.4005e-01,  9.2784e-02, -1.1816e-01,\n",
       "           6.1606e-02,  1.8208e-01, -2.2639e-01, -1.1868e-01,  2.0193e-01,\n",
       "          -2.1913e-01, -3.4252e-02, -9.4581e-02, -4.6286e-02,  1.0530e-02,\n",
       "          -9.9440e-03],\n",
       "         [ 6.3141e-02, -6.3665e-02, -4.9112e-02, -4.3772e-01, -3.6409e-01,\n",
       "           1.0108e-02,  1.2307e-02,  1.0648e-02, -3.8588e-02, -6.3994e-02,\n",
       "           1.9627e-01, -3.0710e-02,  1.9798e-01,  1.5218e-01,  2.2407e-02,\n",
       "           1.5378e-03],\n",
       "         [ 1.1167e-01, -3.2691e-02, -1.7810e-01,  1.1071e-01, -4.1910e-02,\n",
       "           1.7114e-01, -1.8033e-39, -4.2278e-39, -2.7790e-01, -6.2614e-02,\n",
       "          -7.4529e-02,  1.5491e-01, -1.2230e-01, -2.0758e-01,  4.9145e-03,\n",
       "           1.5351e-39],\n",
       "         [ 8.4908e-02, -7.7403e-02,  7.6331e-02, -1.5153e-01, -9.5437e-02,\n",
       "          -4.0066e-01,  7.2655e-02,  4.9747e-02,  1.8518e-01, -5.2716e-02,\n",
       "           1.6119e-01,  1.3304e-01,  5.4289e-02, -1.4861e-01, -1.0636e-02,\n",
       "          -2.8869e-03],\n",
       "         [-1.4277e-01,  2.5018e-01,  5.8576e-02, -9.9070e-02, -1.8165e-01,\n",
       "           6.8912e-02, -1.5454e-01,  1.1935e-01, -1.1266e-01,  1.0321e-02,\n",
       "           4.9199e-02,  9.4849e-02, -3.0795e-02,  4.1420e-02, -7.2727e-02,\n",
       "           2.7833e-38],\n",
       "         [-2.5899e-04,  1.8414e-01,  6.4061e-02, -5.5102e-02, -1.2318e-01,\n",
       "          -5.3742e-02, -1.4013e-01,  4.8553e-03, -2.1691e-01,  1.8016e-01,\n",
       "           1.7731e-01,  3.2294e-02, -1.2466e-01, -2.5024e-01, -5.2086e-39,\n",
       "          -9.9823e-40],\n",
       "         [-1.5824e-02, -4.0847e-03,  1.2428e-02, -8.5268e-03,  5.4255e-03,\n",
       "          -2.2055e-04, -7.0155e-03, -1.1273e-02, -5.0314e-02, -4.8578e-02,\n",
       "          -1.5586e-02, -1.9666e-03, -5.8675e-02, -6.2733e-03, -5.4132e-39,\n",
       "          -2.4327e-39]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-6.5091e-02, -2.6028e-01, -8.4317e-01,  5.3050e-01, -2.6167e-01,\n",
       "         -1.5988e-01, -1.1505e-01, -1.1673e-01,  9.7781e-02,  5.8369e-01,\n",
       "          3.3949e-01,  3.2121e-02, -5.8036e-01,  4.1997e-01,  1.9841e-01,\n",
       "          4.6971e-05], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.1064, -0.1053, -0.1052,  0.1399, -0.0104, -0.0166, -0.1364, -0.0054,\n",
       "           0.1483,  0.2356,  0.1382,  0.1604, -0.0626,  0.2071,  0.0951, -0.0100]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.7416], requires_grad=True)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = list(classificador.parameters())\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 30])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pesos0 = params[0]\n",
    "pesos0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias0 = params[1]\n",
    "bias0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 16])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pesos1 = params[2]\n",
    "pesos1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias1 = params[3]\n",
    "bias1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etapa 7: Avaliação do modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=30, out_features=16, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=16, out_features=16, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=16, out_features=1, bias=True)\n",
       "  (5): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificador.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(previsores_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsores_teste = torch.tensor(np.array(previsores_teste), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(previsores_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = classificador.forward(previsores_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.9343e-01],\n",
       "        [1.0000e+00],\n",
       "        [4.4810e-01],\n",
       "        [9.6889e-01],\n",
       "        [2.4190e-04],\n",
       "        [8.5552e-01],\n",
       "        [9.4859e-01],\n",
       "        [9.9976e-01],\n",
       "        [6.9172e-01],\n",
       "        [6.2148e-01],\n",
       "        [9.4319e-01],\n",
       "        [9.9781e-01],\n",
       "        [9.8115e-01],\n",
       "        [9.9566e-01],\n",
       "        [9.9528e-01],\n",
       "        [8.4966e-01],\n",
       "        [9.9589e-01],\n",
       "        [1.0000e+00],\n",
       "        [3.8435e-01],\n",
       "        [9.9654e-01],\n",
       "        [2.4737e-10],\n",
       "        [1.3299e-02],\n",
       "        [5.1388e-01],\n",
       "        [1.0000e+00],\n",
       "        [9.1471e-01],\n",
       "        [5.1335e-03],\n",
       "        [8.2585e-01],\n",
       "        [1.0000e+00],\n",
       "        [2.1750e-04],\n",
       "        [9.9790e-01],\n",
       "        [5.3644e-01],\n",
       "        [9.9999e-01],\n",
       "        [8.8585e-01],\n",
       "        [9.8646e-01],\n",
       "        [4.7128e-01],\n",
       "        [9.9816e-01],\n",
       "        [6.3675e-01],\n",
       "        [9.9854e-01],\n",
       "        [9.9834e-01],\n",
       "        [2.1024e-05],\n",
       "        [5.3622e-03],\n",
       "        [9.4315e-01],\n",
       "        [4.3994e-08],\n",
       "        [3.4081e-01],\n",
       "        [4.0611e-05],\n",
       "        [6.2099e-01],\n",
       "        [3.2823e-04],\n",
       "        [2.6164e-31],\n",
       "        [6.8410e-01],\n",
       "        [2.0183e-02],\n",
       "        [9.5082e-01],\n",
       "        [2.4065e-15],\n",
       "        [9.7806e-01],\n",
       "        [9.5809e-01],\n",
       "        [9.9371e-01],\n",
       "        [6.3280e-01],\n",
       "        [9.9984e-01],\n",
       "        [3.4695e-08],\n",
       "        [1.9075e-06],\n",
       "        [9.8856e-01],\n",
       "        [6.9911e-05],\n",
       "        [9.9751e-01],\n",
       "        [9.9022e-01],\n",
       "        [9.9558e-01],\n",
       "        [6.4670e-01],\n",
       "        [3.1191e-08],\n",
       "        [1.0000e+00],\n",
       "        [1.0000e+00],\n",
       "        [1.0000e+00],\n",
       "        [7.5260e-01],\n",
       "        [1.0000e+00],\n",
       "        [9.7058e-01],\n",
       "        [1.2501e-01],\n",
       "        [9.1762e-01],\n",
       "        [4.4634e-04],\n",
       "        [9.9829e-01],\n",
       "        [9.4305e-01],\n",
       "        [3.2772e-10],\n",
       "        [8.3503e-06],\n",
       "        [3.3516e-01],\n",
       "        [8.8140e-01],\n",
       "        [5.4393e-06],\n",
       "        [4.9430e-07],\n",
       "        [9.9298e-01],\n",
       "        [1.0000e+00],\n",
       "        [1.0000e+00],\n",
       "        [1.6033e-01],\n",
       "        [9.9577e-01],\n",
       "        [1.8276e-03],\n",
       "        [7.3605e-01],\n",
       "        [1.7216e-02],\n",
       "        [9.8314e-01],\n",
       "        [9.7577e-01],\n",
       "        [2.7056e-02],\n",
       "        [9.9673e-01],\n",
       "        [9.9994e-01],\n",
       "        [9.9962e-01],\n",
       "        [9.9542e-01],\n",
       "        [9.6490e-03],\n",
       "        [1.0000e+00],\n",
       "        [9.9992e-01],\n",
       "        [1.0000e+00],\n",
       "        [9.9786e-01],\n",
       "        [9.8215e-01],\n",
       "        [9.6472e-01],\n",
       "        [1.0000e+00],\n",
       "        [1.0000e+00],\n",
       "        [9.9228e-01],\n",
       "        [1.0000e+00],\n",
       "        [9.9723e-01],\n",
       "        [1.0000e+00],\n",
       "        [9.9996e-01],\n",
       "        [8.5174e-01],\n",
       "        [1.3340e-05],\n",
       "        [9.3609e-01],\n",
       "        [4.2672e-04],\n",
       "        [9.9859e-01],\n",
       "        [1.0454e-03],\n",
       "        [9.9809e-01],\n",
       "        [9.9574e-01],\n",
       "        [8.6672e-01],\n",
       "        [7.4715e-01],\n",
       "        [9.9980e-01],\n",
       "        [9.9867e-01],\n",
       "        [4.0030e-07],\n",
       "        [9.9099e-01],\n",
       "        [2.7443e-03],\n",
       "        [3.4404e-01],\n",
       "        [1.0000e+00],\n",
       "        [9.9550e-01],\n",
       "        [6.7297e-10],\n",
       "        [9.1421e-01],\n",
       "        [1.0000e+00],\n",
       "        [2.5719e-02],\n",
       "        [4.8637e-06],\n",
       "        [9.6173e-01],\n",
       "        [9.9016e-01],\n",
       "        [9.9975e-01],\n",
       "        [8.9556e-02],\n",
       "        [9.3790e-06],\n",
       "        [4.4043e-06],\n",
       "        [9.9445e-01],\n",
       "        [1.0659e-11]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(previsoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = np.array(previsoes > 0.5) # maior que 0.5 é um menor é 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9020979020979021"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxa_acerto = accuracy_score(classe_teste, previsoes)\n",
    "taxa_acerto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[43, 11],\n",
       "       [ 3, 86]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matriz = confusion_matrix(classe_teste, previsoes)\n",
    "matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(matriz, annot=True);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "748b4bbb40e1dc38591514fffe1d01ec0f0710858425568fad37763828692ea0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
